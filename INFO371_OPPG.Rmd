---
title: "INFO371_SEM_OPPG"
output: html_document
date: "2023-05-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Library og load ting

```{r}
#update.packages(ask = FALSE)
library(readtext)
library(tidyverse)
library(quanteda)
library(stopwords)
library(dplyr)
library(ggplot2)
library(tidytext)
library(pdftools)
library(quanteda.textmodels)
library(quanteda.textstats)
install.packages("seededlda")
library(seededlda)

dat_raw <- readtext("Commission consultation all/*")

table(dat_raw$doc_id)

dat <- dat_raw |> 
    mutate(text = str_squish(text)) |> # remove unnecessary whitespace
    separate(doc_id, into = c("id", "actor", "type_actor"),
             sep = "_") # create docvars based on file names

# remove PDF ending in document-level variable
dat <- dat |> 
    mutate(type_actor = str_remove_all(type_actor, "\\.pdf"))


# save as RDS file
saveRDS(dat, "data_corpus_aiact.rds")
```


## Visualisering av PDFene

```{r echo=FALSE}
ai_act <- readRDS("data_corpus_aiact.rds")
ai_act
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
toks_act <- ntoken(ai_act)
```

```{r}
sim_1 <- corpus(ai_act) %>%
  tokens(remove_punct = TRUE) %>%
  tokens_remove(pattern = stopwords('en')) %>%
  tokens_wordstem() %>%
  dfm() %>%
  dfm_group (groups = actor) %>%
  textstat_simil(method = 'cosine', margin ='documents')
sim_1

```

```{r}
#Topic modelling
topic_council <- corpus(corp_council) %>%
    tokens(remove_punct = TRUE,
           remove_symbol = TRUE,
           remove_numbers = TRUE) %>%
      tokens_replace(pattern = lexicon::hash_lemmas$token, replacement = lexicon::hash_lemmas$lemma)%>%
  #Legg til unødvendige terms her
  tokens_remove(pattern = c(stopwords('en'),
                            'xx','shall','b',
                            'en','use','put',
                            'ec','rb', 'ek',
                            'set','datum', 'iii',
                            'oj', 'also','can',
                            'p')) %>%
  dfm() %>%
  #Endre termfreq, 0.8 = top 20% most frequent
  dfm_trim(min_termfreq = 0.8,
           termfreq_type = "quantile")

topic_aiact <- corpus(corp_aiact) %>%
    tokens(remove_punct = TRUE,
           remove_symbol = TRUE,
           remove_numbers = TRUE) %>%
    tokens_replace(pattern = lexicon::hash_lemmas$token, replacement = lexicon::hash_lemmas$lemma)%>%
  #Legg til unødvendige terms her
  tokens_remove(pattern = c(stopwords('en'),
                            'xx','shall','b',
                            'en','use','put',
                            'ec','rb', 'ek',
                            'set','datum', 'iii',
                            'oj', 'also','can',
                            'p')) %>%
  dfm() %>%
  #Endre termfreq, 0.8 = top 20% most frequent
  dfm_trim(min_termfreq = 0.8,
           termfreq_type = "quantile")

#k = number of topics
tmod_lda_council <- textmodel_lda(topic_council, k = 8)
tmod_lda_aiact <- textmodel_lda(topic_aiact, k = 8)

# tallet = number of terms
terms(tmod_lda_council, 10)
terms(tmod_lda_aiact, 10)

```

```{r}
```
