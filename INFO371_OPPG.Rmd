---
title: "INFO371_SEM_OPPG"
output: html_document
date: "2023-05-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Library og load ting

```{r}
#install.packages("keyATM")
#install.packages('seededlda')
#install.packages('readtext')
#install.packages('quanteda')
#install.packages('tidytext')

library(readtext)
library(tidyverse)
library(quanteda)
library(stopwords)
library(dplyr)
library(ggplot2)
library(tidytext)
library(pdftools)
library(quanteda.textmodels)
library(quanteda.textstats)
library(keyATM)
library(seededlda)

corp_aiact <- readtext("AI_Act_Commission.pdf")
corp_council <- readtext("Council statement Fall  2022 - ST-14954-2022-INIT_en.pdf")

# for det er fredag min venn
#commi_pdf <- pdftools::pdf_text(pdf = "AI_Act_Commission.pdf")
#counc_pdf <- pdftools::pdf_text(pdf = "Council statement Fall  2022 - ST-14954-2022-INIT_en.pdf")


dat_raw <- readtext("Commission consultation all/Council statement Fall  2022 - ST-14954-2022-INIT_en.pdf")

table(dat_raw$doc_id)

dat <- dat_raw |> 
    mutate(text = str_squish(text)) |> # remove unnecessary whitespace
    separate(doc_id, into = c("id", "actor", "type_actor"),
             sep = "_") # create docvars based on file names

# remove PDF ending in document-level variable
dat <- dat |> 
    mutate(type_actor = str_remove_all(type_actor, "\\.pdf"))


# save as RDS file
saveRDS(dat, "data_corpus_aiact.rds")
```


## Visualisering av PDFene

```{r echo=FALSE}
ai_act <- readRDS("data_corpus_aiact.rds")
ai_act
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
corp_c <- readtext()
```

```{r}
sim_1 <- corpus(ai_act) %>%
  tokens(remove_punct = TRUE) %>%
  tokens_remove(pattern = stopwords('en')) %>%
  tokens_wordstem() %>%
  dfm() %>%
  dfm_group (groups = actor) %>%
  textstat_simil(method = 'cosine', margin ='documents')
sim_1

```

```{r}
#Topic modelling
topic_council <- corpus(corp_council) %>%
    tokens(remove_punct = TRUE,
           remove_symbol = TRUE,
           remove_numbers = TRUE) %>%
      tokens_replace(pattern = lexicon::hash_lemmas$token, replacement = lexicon::hash_lemmas$lemma)%>%
  #Legg til unødvendige terms her
  tokens_remove(pattern = c(stopwords('en'),
                            'xx','shall','b',
                            'en','use','put',
                            'ec','rb', 'ek',
                            'set','datum', 'iii',
                            'oj', 'also','can',
                            'p')) %>%
  dfm() %>%
  #Endre termfreq, 0.8 = top 20% most frequent
  dfm_trim(min_termfreq = 0.8,
           termfreq_type = "quantile")

topic_aiact <- corpus(corp_aiact) %>%
    tokens(remove_punct = TRUE,
           remove_symbol = TRUE,
           remove_numbers = TRUE) %>%
    tokens_replace(pattern = lexicon::hash_lemmas$token, replacement = lexicon::hash_lemmas$lemma)%>%
  #Legg til unødvendige terms her
  tokens_remove(pattern = c(stopwords('en'),
                            'xx','shall','b',
                            'en','use','put',
                            'ec','rb', 'ek',
                            'set','datum', 'iii',
                            'oj', 'also','can',
                            'p')) %>%
  dfm() %>%
  #Endre termfreq, 0.8 = top 20% most frequent
  dfm_trim(min_termfreq = 0.8,
           termfreq_type = "quantile")

#k = number of topics
tmod_lda_council <- textmodel_lda(topic_council, k = 8)
tmod_lda_aiact <- textmodel_lda(topic_aiact, k = 8)

# tallet = number of terms
terms(tmod_lda_council, 10)
terms(tmod_lda_aiact, 10)

topic_council$topic <- topics(tmod_lda_council)
table(topic_council$topic)

topic_aiact$topic <- topics(tmod_lda_aiact)
table(topic_aiact$topic)

```

```{r}
#UDpipe
library(udpipe)
install.packages('udpipe')

#Downloading model
dl <- udpipe_download_model(language = 'english')
str(dl)

#Loading model
udmodel_english <- udpipe_load_model(file = 'english-ewt-ud-2.5-191206.udpipe')

udmodel_council <- udpipe_annotate(udmodel_english, x = corp_council$text) %>%
  as.data.frame(udmodel_council)


str(udmodel_council)


#Cleaning the lemma column
#list of stopwords
stops <- c(stopwords('en'),
           'xx','shall','b',
           'en','use','put',
           'ec','rb', 'ek',
           'set','datum', 'iii',
           'oj', 'also','can',
           'p')
#regex to remove symbols and numbers
udmodel_council <- udmodel_council[-grep('[^A-Za-z]', udmodel_council$lemma),]

#Chaning data to lowercase and token-objects
udmodel_council$lemma <- tolower(udmodel_council$lemma)
udmodel_council$lemma <- tokens(udmodel_council$lemma)

#create placeholder in order to keep index when replacig
na <- rep('$$', length(stops))

#replace unwanted tokens
udmodel_council$lemma <- tokens_replace(udmodel_council$lemma,
                             pattern = stops,
                             na)

#regex to remove rows with unwanted tokens
udmodel_council <- udmodel_council[-grep('[^A-Za-z]',udmodel_council$lemma),]
```
